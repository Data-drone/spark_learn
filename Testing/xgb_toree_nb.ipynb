{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark / Toree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.types.{DoubleType, StringType, StructField, StructType}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@4d2634d1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@4d2634d1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder().config(\"spark.executor.memory\", \"2g\")\n",
    "                    .config(\"spark.driver.memory\", \"4g\")\n",
    "                    .config(\"spark.jars.packages\",\"ml.dmlc.xgboost4j_2.11:1.0.0\")\n",
    "                    .config(\"spark.jars.packages\",\"ml.dmlc.xgboost4j-spark_2.11:1.0.0\")\n",
    "                    .master(\"spark://spark-master:7077\").getOrCreate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download from file:/opt/spark-data/libs/xgb_1/xgboost4j_2.11-1.0.0.jar\n",
      "Finished download of xgboost4j_2.11-1.0.0.jar\n",
      "Starting download from file:/opt/spark-data/libs/xgb_1/xgboost4j-spark_2.11-1.0.0.jar\n",
      "Finished download of xgboost4j-spark_2.11-1.0.0.jar\n"
     ]
    }
   ],
   "source": [
    "%AddJar file:/opt/spark-data/libs/xgb_1/xgboost4j_2.11-1.0.0.jar\n",
    "%AddJar file:/opt/spark-data/libs/xgb_1/xgboost4j-spark_2.11-1.0.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema = StructType(StructField(sepal length,DoubleType,true), StructField(sepal width,DoubleType,true), StructField(petal length,DoubleType,true), StructField(petal width,DoubleType,true), StructField(class,StringType,true))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(sepal length,DoubleType,true), StructField(sepal width,DoubleType,true), StructField(petal length,DoubleType,true), StructField(petal width,DoubleType,true), StructField(class,StringType,true))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = new StructType(Array(\n",
    "  StructField(\"sepal length\", DoubleType, true),\n",
    "  StructField(\"sepal width\", DoubleType, true),\n",
    "  StructField(\"petal length\", DoubleType, true),\n",
    "  StructField(\"petal width\", DoubleType, true),\n",
    "  StructField(\"class\", StringType, true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rawInput = [sepal length: double, sepal width: double ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[sepal length: double, sepal width: double ... 3 more fields]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rawInput = spark.read\n",
    "                    .option(\"header\", \"true\")\n",
    "                    .schema(schema).csv(\"/opt/spark-data/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+------+\n",
      "|sepal length|sepal width|petal length|petal width| class|\n",
      "+------------+-----------+------------+-----------+------+\n",
      "|         5.1|        3.5|         1.4|        0.2|setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2|setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2|setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4|setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3|setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2|setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2|setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1|setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2|setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2|setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1|setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1|setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2|setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4|setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4|setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3|setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3|setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3|setosa|\n",
      "+------------+-----------+------------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawInput.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[sepal length: double, sepal width: double ... 3 more fields]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawInput.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stringIndexer = strIdx_ebba540feecd\n",
       "labelTransformed = [sepal length: double, sepal width: double ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[sepal length: double, sepal width: double ... 3 more fields]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "val stringIndexer = new StringIndexer().\n",
    "  setInputCol(\"class\").\n",
    "  setOutputCol(\"classIndex\").\n",
    "  fit(rawInput)\n",
    "val labelTransformed = stringIndexer.transform(rawInput).drop(\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vectorAssembler = vecAssembler_5c8e139f3bc6\n",
       "xgbInput = [features: vector, classIndex: double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[features: vector, classIndex: double]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "val vectorAssembler = new VectorAssembler().\n",
    "  setInputCols(Array(\"sepal length\", \"sepal width\", \"petal length\", \"petal width\")).\n",
    "  setOutputCol(\"features\")\n",
    "val xgbInput = vectorAssembler.transform(labelTransformed).select(\"features\", \"classIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgbParam = Map(num_workers -> 2, num_class -> 3, objective -> multi:softprob, num_round -> 100, missing -> -999, eta -> 0.1)\n",
       "xgbClassifier = xgbc_335a7be2015b\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "xgbc_335a7be2015b"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ml.dmlc.xgboost4j.scala.spark.XGBoostClassifier\n",
    "val xgbParam = Map(\"eta\" -> 0.1f,\n",
    "      \"missing\" -> -999,\n",
    "      \"objective\" -> \"multi:softprob\",\n",
    "      \"num_class\" -> 3,\n",
    "      \"num_round\" -> 100,\n",
    "      \"num_workers\" -> 2)\n",
    "val xgbClassifier = new XGBoostClassifier(xgbParam).\n",
    "      setFeaturesCol(\"features\").\n",
    "      setLabelCol(\"classIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgbc_335a7be2015b"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbClassifier.setMaxDepth(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=172.22.0.3, DMLC_TRACKER_PORT=9091, DMLC_NUM_WORKER=2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name: ml.dmlc.xgboost4j.java.XGBoostError\n",
       "Message: XGBoostModel training failed\n",
       "StackTrace:   at ml.dmlc.xgboost4j.scala.spark.XGBoost$.postTrackerReturnProcessing(XGBoost.scala:697)\n",
       "  at ml.dmlc.xgboost4j.scala.spark.XGBoost$.trainDistributed(XGBoost.scala:572)\n",
       "  at ml.dmlc.xgboost4j.scala.spark.XGBoostClassifier.train(XGBoostClassifier.scala:190)\n",
       "  at ml.dmlc.xgboost4j.scala.spark.XGBoostClassifier.train(XGBoostClassifier.scala:40)\n",
       "  at org.apache.spark.ml.Predictor.fit(Predictor.scala:118)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val xgbClassificationModel = xgbClassifier.fit(xgbInput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
