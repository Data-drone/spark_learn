{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Workbook\n",
    "splitting it out cause it's more complicated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this works with the 0.72 but not 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://repo1.maven.org/maven2/ml/dmlc/xgboost4j/0.72/xgboost4j-0.72.jar -O ../data/libs/xgboost4j-0.72.jar\n",
    "!wget https://repo1.maven.org/maven2/ml/dmlc/xgboost4j-spark/0.72/xgboost4j-spark-0.72.jar -O ../data/libs/xgboost4j-spark-0.72.jar\n",
    "#!wget https://github.com/dmlc/xgboost/files/2161553/sparkxgb.zip -O ../data/libs/sparkxgb.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/spark-data/libs/xgboost4j-0.90.jar: Permission denied\n",
      "/opt/spark-data/libs/xgboost4j-spark-0.90.jar: Permission denied\n"
     ]
    }
   ],
   "source": [
    "!wget https://repo1.maven.org/maven2/ml/dmlc/xgboost4j/0.90/xgboost4j-0.90.jar -O /opt/spark-data/libs/xgboost4j-0.90.jar\n",
    "!wget https://repo1.maven.org/maven2/ml/dmlc/xgboost4j-spark/0.90/xgboost4j-spark-0.90.jar -O /opt/spark-data/libs/xgboost4j-spark-0.90.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/spark-data/libs/pyspark-xgboost.zip: Permission denied\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/dmlc/xgboost/files/3384356/pyspark-xgboost_0.90_261ab52e07bec461c711d209b70428ab481db470.zip -O /opt/spark-data/libs/pyspark-xgboost.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /opt/spark-data/libs/xgboost4j-spark-0.90.jar,/opt/spark-data/libs/xgboost4j-0.90.jar pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"PySpark xgb new\")\\\n",
    "        .master(\"spark://spark-master:7077\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost4j-0.90.jar  xgboost4j-spark-0.90.jar\n"
     ]
    }
   ],
   "source": [
    "!ls /opt/spark-data/libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.addPyFile(\"/opt/spark-data/libs/pyspark-xgboost.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.read.format(\"libsvm\").load(\"/opt/spark-data/iris.scale\")\n",
    "# split dataset into train and test\n",
    "train, test = dataset.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets look at one entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset.select(\"features\")) #.toDense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,2,3],[-0.77...|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-1....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "|  1.0|(4,[0,1,2,3],[-0....|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "schema = StructType([\n",
    "            StructField(\"sepal length\", DoubleType(), True),\n",
    "            StructField(\"sepal width\", DoubleType(), True),\n",
    "            StructField(\"petal length\", DoubleType(), True),\n",
    "            StructField(\"petal width\", DoubleType(), True),\n",
    "            StructField(\"class\", StringType(), True)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawInput = spark.read.schema(schema).csv(\"/opt/spark-data/iris.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal length|sepal width|petal length|petal width|      class|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4|Iris-setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3|Iris-setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2|Iris-setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1|Iris-setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2|Iris-setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2|Iris-setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1|Iris-setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1|Iris-setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2|Iris-setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4|Iris-setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4|Iris-setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3|Iris-setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3|Iris-setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawInput.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal length: double (nullable = true)\n",
      " |-- sepal width: double (nullable = true)\n",
      " |-- petal length: double (nullable = true)\n",
      " |-- petal width: double (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawInput.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol=\"class\", outputCol=\"classIndex\")\n",
    "model = stringIndexer.fit(rawInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelTransformed = model.transform(rawInput).drop(\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+----------+\n",
      "|sepal length|sepal width|petal length|petal width|classIndex|\n",
      "+------------+-----------+------------+-----------+----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|       0.0|\n",
      "|         4.9|        3.0|         1.4|        0.2|       0.0|\n",
      "|         4.7|        3.2|         1.3|        0.2|       0.0|\n",
      "|         4.6|        3.1|         1.5|        0.2|       0.0|\n",
      "|         5.0|        3.6|         1.4|        0.2|       0.0|\n",
      "|         5.4|        3.9|         1.7|        0.4|       0.0|\n",
      "|         4.6|        3.4|         1.4|        0.3|       0.0|\n",
      "|         5.0|        3.4|         1.5|        0.2|       0.0|\n",
      "|         4.4|        2.9|         1.4|        0.2|       0.0|\n",
      "|         4.9|        3.1|         1.5|        0.1|       0.0|\n",
      "|         5.4|        3.7|         1.5|        0.2|       0.0|\n",
      "|         4.8|        3.4|         1.6|        0.2|       0.0|\n",
      "|         4.8|        3.0|         1.4|        0.1|       0.0|\n",
      "|         4.3|        3.0|         1.1|        0.1|       0.0|\n",
      "|         5.8|        4.0|         1.2|        0.2|       0.0|\n",
      "|         5.7|        4.4|         1.5|        0.4|       0.0|\n",
      "|         5.4|        3.9|         1.3|        0.4|       0.0|\n",
      "|         5.1|        3.5|         1.4|        0.3|       0.0|\n",
      "|         5.7|        3.8|         1.7|        0.3|       0.0|\n",
      "|         5.1|        3.8|         1.5|        0.3|       0.0|\n",
      "+------------+-----------+------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelTransformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler = VectorAssembler(inputCols=[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"],\n",
    "                                  outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbInput = vectorAssembler.transform(labelTransformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+----------+-----------------+\n",
      "|sepal length|sepal width|petal length|petal width|classIndex|         features|\n",
      "+------------+-----------+------------+-----------+----------+-----------------+\n",
      "|         5.1|        3.5|         1.4|        0.2|       0.0|[5.1,3.5,1.4,0.2]|\n",
      "|         4.9|        3.0|         1.4|        0.2|       0.0|[4.9,3.0,1.4,0.2]|\n",
      "|         4.7|        3.2|         1.3|        0.2|       0.0|[4.7,3.2,1.3,0.2]|\n",
      "|         4.6|        3.1|         1.5|        0.2|       0.0|[4.6,3.1,1.5,0.2]|\n",
      "|         5.0|        3.6|         1.4|        0.2|       0.0|[5.0,3.6,1.4,0.2]|\n",
      "|         5.4|        3.9|         1.7|        0.4|       0.0|[5.4,3.9,1.7,0.4]|\n",
      "|         4.6|        3.4|         1.4|        0.3|       0.0|[4.6,3.4,1.4,0.3]|\n",
      "|         5.0|        3.4|         1.5|        0.2|       0.0|[5.0,3.4,1.5,0.2]|\n",
      "|         4.4|        2.9|         1.4|        0.2|       0.0|[4.4,2.9,1.4,0.2]|\n",
      "|         4.9|        3.1|         1.5|        0.1|       0.0|[4.9,3.1,1.5,0.1]|\n",
      "|         5.4|        3.7|         1.5|        0.2|       0.0|[5.4,3.7,1.5,0.2]|\n",
      "|         4.8|        3.4|         1.6|        0.2|       0.0|[4.8,3.4,1.6,0.2]|\n",
      "|         4.8|        3.0|         1.4|        0.1|       0.0|[4.8,3.0,1.4,0.1]|\n",
      "|         4.3|        3.0|         1.1|        0.1|       0.0|[4.3,3.0,1.1,0.1]|\n",
      "|         5.8|        4.0|         1.2|        0.2|       0.0|[5.8,4.0,1.2,0.2]|\n",
      "|         5.7|        4.4|         1.5|        0.4|       0.0|[5.7,4.4,1.5,0.4]|\n",
      "|         5.4|        3.9|         1.3|        0.4|       0.0|[5.4,3.9,1.3,0.4]|\n",
      "|         5.1|        3.5|         1.4|        0.3|       0.0|[5.1,3.5,1.4,0.3]|\n",
      "|         5.7|        3.8|         1.7|        0.3|       0.0|[5.7,3.8,1.7,0.3]|\n",
      "|         5.1|        3.8|         1.5|        0.3|       0.0|[5.1,3.8,1.5,0.3]|\n",
      "+------------+-----------+------------+-----------+----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgbInput.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbInput = xgbInput.select(\"features\", \"classIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = xgbInput.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|         features|classIndex|\n",
      "+-----------------+----------+\n",
      "|[4.3,3.0,1.1,0.1]|       0.0|\n",
      "|[4.6,3.1,1.5,0.2]|       0.0|\n",
      "|[4.6,3.2,1.4,0.2]|       0.0|\n",
      "|[4.6,3.4,1.4,0.3]|       0.0|\n",
      "|[4.6,3.6,1.0,0.2]|       0.0|\n",
      "|[4.7,3.2,1.3,0.2]|       0.0|\n",
      "|[4.7,3.2,1.6,0.2]|       0.0|\n",
      "|[4.8,3.0,1.4,0.1]|       0.0|\n",
      "|[4.8,3.0,1.4,0.3]|       0.0|\n",
      "|[4.8,3.1,1.6,0.2]|       0.0|\n",
      "|[4.9,2.4,3.3,1.0]|       1.0|\n",
      "|[4.9,2.5,4.5,1.7]|       2.0|\n",
      "|[4.9,3.0,1.4,0.2]|       0.0|\n",
      "|[4.9,3.1,1.5,0.1]|       0.0|\n",
      "|[4.9,3.1,1.5,0.1]|       0.0|\n",
      "|[5.0,2.0,3.5,1.0]|       1.0|\n",
      "|[5.0,3.0,1.6,0.2]|       0.0|\n",
      "|[5.0,3.4,1.5,0.2]|       0.0|\n",
      "|[5.0,3.5,1.6,0.6]|       0.0|\n",
      "|[5.0,3.6,1.4,0.2]|       0.0|\n",
      "+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load xgb module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparkxgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = sparkxgb.XGBoostClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"classIndex\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBoostClassifier_aab4e831cba1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.setParams(eta=0.1,\n",
    "                   maxDepth=2,\n",
    "                   objective=\"multi:softprob\",\n",
    "                   numClass=3,\n",
    "                   numRound=100,\n",
    "                   numWorkers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb_model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
